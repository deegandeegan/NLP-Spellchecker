{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2oP1uun77cIh"
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "This assignment will involve the creation of a spellchecking system and an evaluation of its performance. You may use the code snippets provided in Python for completing this or you may use the programming language or environment of your choice\n",
    "\n",
    "Please start by downloading the corpus `holbrook.txt` from Blackboard\n",
    "\n",
    "The file consists of lines of text, with one sentence per line. Errors in the line are marked with a `|` as follows\n",
    "\n",
    "    My siter|sister go|goes to Tonbury .\n",
    "    \n",
    "In this case the word 'siter' was corrected to 'sister' and the word 'go' was corrected to 'goes'.\n",
    "\n",
    "In some places in the corpus two words maybe corrected to a single word or one word to a multiple words. This is denoted in the data using underscores e.g.,\n",
    "\n",
    "    My Mum goes out some_times|sometimes .\n",
    "    \n",
    "For the purpose of this assignment you do not need to separate these words, but instead you may treat them like a single token.\n",
    "\n",
    "*Note: you may use any functions from NLTK to complete the assignment. It should not be necessary to use other libraries and so please consult with us if your solution involves any other external library. If you use any function from NLTK in Task 6 please include a brief description of this function and how it contributes to your solution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIVCSJV-7kDs"
   },
   "source": [
    "## Task 1 (10 Marks)\n",
    "\n",
    "Write a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n",
    "\n",
    "Then split your data into a test set of 100 lines and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RznCZ1mw7mfk"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'siter', '.'], 'corrected': ['I', 'have', 'four', 'in', 'my', 'Family', 'Dad', 'Mum', 'and', 'sister', '.'], 'indexes': [9]}\n"
     ]
    }
   ],
   "source": [
    "# Create parser function\n",
    "def parse(text):\n",
    "\n",
    "    # Create empty lists\n",
    "    line_original = []\n",
    "    line_corrected = []\n",
    "    Index = []\n",
    "    count = 0\n",
    "\n",
    "    # create a for loop that goes through each line in the text\n",
    "    for line in text:\n",
    "        if '|' in line:\n",
    "            # If sentence has '|', then split\n",
    "            string = line.split('|')\n",
    "            # Word before '|' store in line_original\n",
    "            line_original.append(string[0])\n",
    "            # Word after '|' store in line_original\n",
    "            line_corrected.append(string[1])\n",
    "            # Append count into Index where error occured\n",
    "            Index.append(count)\n",
    "\n",
    "        else:\n",
    "            # If sentence does not include '|', then sentence is stored in both original & corrected as it is.\n",
    "            line_original.append(line)\n",
    "            line_corrected.append(line)\n",
    "        count = count + 1\n",
    "\n",
    "    #Loading to original, correct and index list to a dictionary\n",
    "    dictionary = {'original' : line_original, 'corrected' : line_corrected, 'indexes' : Index}\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "# Create preprocess_data function\n",
    "def preprocess_data():\n",
    "    # Initialize data\n",
    "    data = []\n",
    "\n",
    "    # Reading the txt file\n",
    "    txt_file = open(\"holbrook.txt\", \"r\")\n",
    "    # Initialize lines\n",
    "    lines = []\n",
    "\n",
    "    for x in txt_file:\n",
    "        lines.append(x.strip())\n",
    "\n",
    "    # Using nltk package to tokenize sentences\n",
    "    sentences = [nltk.word_tokenize(sentence) for sentence in lines]\n",
    "\n",
    "\n",
    "    # Now implementing parser() function,\n",
    "    # which was created to generate corrected & original sentences & index\n",
    "    for sentence in sentences:\n",
    "        data.append(parse(sentence))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Calling postprocessing function\n",
    "processed_data = preprocess_data()\n",
    "\n",
    "# Test parser\n",
    "print(processed_data[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRSX4I0H7pSC"
   },
   "source": [
    "The counts and assertions given in the following sections are based on splitting the training and test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Kt9aR2Gy7p1C"
   },
   "outputs": [],
   "source": [
    "test = processed_data[:100]\n",
    "train = processed_data[100:]\n",
    "words_correct = [index['corrected'] for index in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hm5JL7cH7sLK"
   },
   "source": [
    "## **Task 2** (10 Marks): \n",
    "Calculate the frequency (number of occurrences), *ignoring case*, of all words and their unigram probability from the corrected *training* sentences.\n",
    "\n",
    "*Hint: use `Counter` to implement this so it may be called many times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ge0uHS-7uEK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_unigram_model(words_correct):\n",
    "    # initialize empty list \n",
    "    text = []\n",
    "    for word in words_correct:\n",
    "        # convert the list of strings to a string with a space between each\n",
    "        text.append(\" \".join(word).lower())\n",
    "\n",
    "    # same as above\n",
    "    text = \" \".join(text)\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "    # Use FreqDist to calculate text's frequency distribution.\n",
    "    unig_freq = nltk.FreqDist(text)\n",
    "\n",
    "    return unig_freq\n",
    "\n",
    "def prob(word, unigram_model):\n",
    "    total = unigram_model.N()\n",
    "    freq, _ = get_word_stats(word, unigram_model)\n",
    "    return freq / float(total)\n",
    "\n",
    "unigram_model = build_unigram_model(words_correct)\n",
    "\n",
    "count, token_num = get_word_stats('me', unigram_model)\n",
    "\n",
    "\n",
    "# Test your code with the following\n",
    "assert(count == 87)\n",
    "# Another way to test code\n",
    "# print(count)\n",
    "print(prob('me', unigram_model) > prob('test', unigram_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8r8QYj78GPK"
   },
   "source": [
    "## **Task 3** (15 Marks): \n",
    "[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SV9Mu8P38IQE",
    "outputId": "9f29e22b-0f8b-4b92-9d5f-fcde3efec970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "\n",
    "# Edit distance returns the number of changes to transform one word to another\n",
    "print(edit_distance(\"hello\", \"hi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm46Lbiz8K8M"
   },
   "source": [
    "Write a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n",
    "\n",
    "1. Collect the set of all unique tokens in `train`\n",
    "2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n",
    "3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n",
    "\n",
    "*Do not implement edit distance, use the built-in NLTK function `edit_distance`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoilAmFW8PCb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mine', 'mind']\n"
     ]
    }
   ],
   "source": [
    "def min_edit_distance(original_word, all_words):\n",
    "    distances = defaultdict(list)\n",
    "    for word in all_words:\n",
    "        if word != original_word:\n",
    "            # create dictonary where key represents edit distance\n",
    "            # from original word, and value is new word, so\n",
    "            # {1: words one away, 2: words two away}, etc\n",
    "            distance = edit_distance(word, original_word)\n",
    "            distances[distance].append(word)\n",
    "    # find the smallest key, which is the min distance\n",
    "    min_distance = min(distances.keys())\n",
    "    return distances[min_distance]\n",
    "\n",
    "\n",
    "all_words = set()\n",
    "# unique list of all words\n",
    "for sent in words_correct:\n",
    "    for word in sent:\n",
    "        all_words.add(word)\n",
    "\n",
    "print(min_edit_distance('minde', all_words))\n",
    "        \n",
    "# Test your code as follows\n",
    "#assert get_candidates(\"minde\") == ['mine', 'mind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGY-eCkN8TIM"
   },
   "source": [
    "## Task 4 (15 Marks):\n",
    "\n",
    "Write a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *unigram probability*. \n",
    "\n",
    "*Your solution to this should involve `get_candidates`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIGKE4_P8WGP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'white', 'cat']\n"
     ]
    }
   ],
   "source": [
    "def correct(sentence, unigram_model):\n",
    "    # Write your code here\n",
    "    result = []\n",
    "\n",
    "    # for each word\n",
    "    for word in sentence:\n",
    "        # if it's in the model already that means it's correct, so append it\n",
    "        if word in unigram_model:\n",
    "            result.append(word)\n",
    "\n",
    "       # if not, get all the words that are close to it by using min_edit_distance\n",
    "        else:\n",
    "            correction_candidates = min_edit_distance(word, all_words)\n",
    "\n",
    "\n",
    "            # The below loop figures out which of the possible substitutes\n",
    "            # are most common in the dataset, and then appends that substitue\n",
    "            best_prod, best_word = 0, None\n",
    "            for c in correction_candidates:\n",
    "                word_prob = prob(c, unigram_model)\n",
    "                if word_prob > best_prod:\n",
    "                    best_prod = word_prob\n",
    "                    best_word = c\n",
    "            result.append(best_word)\n",
    "    return result\n",
    "\n",
    "print(correct([\"this\",\"whitr\",\"cat\"], unigram_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG7jC6au8kka"
   },
   "source": [
    "## **Task 5** (10 Marks): \n",
    "Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HSXTQypR8mdR",
    "outputId": "853813e4-d71b-42a7-8e96-68d038457628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23728813559322035\n"
     ]
    }
   ],
   "source": [
    "def accuracy(test):\n",
    "    # keep a count of all words that should've been corrected, and how many\n",
    "    # model got right. Everytime model sees a word that was misspelled - increment 'total'\n",
    "    # and if it was right - increment 'correct_count'\n",
    "    correct_count, total = 0.0, 0.0\n",
    "    for sentence in test:\n",
    "        original_sentence = sentence['original']\n",
    "        corrected_sentence = correct(original_sentence, unigram_model)\n",
    "\n",
    "        true_corrected = sentence['corrected']\n",
    "        for idx in sentence['indexes']:\n",
    "            if corrected_sentence[idx] == true_corrected[idx]:\n",
    "                correct_count += 1\n",
    "            total += 1\n",
    "    return correct_count / total\n",
    "\n",
    "print(accuracy(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b-r2JzD8_Zh"
   },
   "source": [
    "## **Task 6 (35 Marks):**\n",
    "\n",
    "Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n",
    "\n",
    "* You may resources beyond those provided here.\n",
    "* You must **not use the test data** in this task.\n",
    "* Provide a short text describing what you intend to do and why. \n",
    "* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n",
    "* Your implementation should not consist of more than 50 lines of code\n",
    "\n",
    "Please note this task is marked according to: demonstration of knowledge from the lecutures (10), originality and appropriateness of solution (10), completeness of description (10) and technical correctness (5)\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Bigram Model (Implemented) \n",
    "\n",
    "The Bigram model is a language model that approximates a probability by using the previous words conditional probability. This type of model of using only the previous word to generate the probability is known as the Markov assumption.  Implementing this modification allowed my language model to gain context when approximating probability, rather than the unigram model which  treats the words as disconnected units via the bag of words perspective. The reason I implemented the Bigram is because it creates a spell checker that prioritizes corrections according to context of the sentence\n",
    "\n",
    "#### 2. Part of Speech Tagging - Hidden Markov Model (Not Implemented)\n",
    "\n",
    "Implementing Part-of-Speech tagging into a language model is the process of assigning part-of-speech tags to each word. To implement this into the language model you first need to tokenize the text (already implemented0 and then tag each token. The tags are generated from a tagset, and the tagset I selected while implement Part-of-speech tagging is 45-tag Penn Treebank as it is the most common in English POS tagging. When creating a spell checker, it is useful to implement Parts-of-speech tagging to the words. Understanding what part of speech the word and its neighbours can help the spell checker by giving higher probability to words that grammatical make sense.\n",
    "\n",
    "A Hidden Markov Model is desirable for part-of-speech tagging tasks as this model calculates the highest probability tag sequence for a given sequence of units (sentences, words, letters, etc.). The goal of HMM tagging is to choose the sequence of tags which is most probable given the observed sequence of words. When juxtaposing HMM and to other part-of-speech tagging techniques HMM is advantageous because it does not take the greedy approach of optimizing words independently.\n",
    "\n",
    "#### 3. Trigram Model (Not Implemented)\n",
    "\n",
    "Implementing the Trigram model would have allowed my model to condition on the previous two words rather than the previous word (bigram). This allows for more context when approximating probabilities. However, since my training data set was small it would have been likely that there would’ve been unseen trigrams.\n",
    "\n",
    "#### 4. Smoothing Technique - Add-one and Backoff (Not Implemented)\n",
    "\n",
    "Originally, I had implemented Add-one smoothing to my upgraded_bigram model. However, this lowered my overall accuracy score. This made me curious, so I decided to read more into smoothing techniques as I was under the assumption that smoothing was going to improve my spell checkers overall accuracy. I will first discuss what Add-one Smoothing is, and then talk about why Backoff smoothing is a more appropriate smoothing technique for my model. \n",
    "\n",
    "Language models assign zero probability to unseen events. Smoothing techniques, such as Add one smoothing, can take care of the zero-probability issue that may arise. Add one smoothing simply adds one to all the bigram counts prior to normalizing them into probabilities. This technique is a non-maximum likelihood estimate because the counts are being altered from their original state in the training data.\n",
    "    \n",
    "    • It is important to note that this technique does have cons – such as the fact that it overestimates low probabilities and underestimates frequent probabilities. \n",
    "\n",
    "\n",
    "While the add one smoothing technique is useful in solving the issues of zero probabilities, the Back-off model has another feature which allows the context provided by a Trigram model to help approximate the probability. In instances where there are no previous instances of a trigram (Wn-2Wn-1Wn) the Back-off technique then uses the bigram probability. This additional feature allows for context to be used in approximating probability. \n",
    "\n",
    "\n",
    "\n",
    "*** (After researching more I ended up taking out add-one smoothing from my model, but wasn't able to add the Backoff Smoothing code due to technical difficulties)\n",
    "\n",
    "#### 5. Real-word Spelling Errors\n",
    "\n",
    "In its current state the implemented spellchecker’s accuracy is determined on its ability to correct misspelled words. However, there are instances when a word is technically spelled correctly, but is grammatical incorrect. The first example this can occur is Typographical errors (typo), which is when the correct spelling of the word is known but there is a typo in the word. (typing there instead of three) The second type of Real Word Error not accounted for in the original spell checker is a Cognitive error. These spelling errors occur in instances where the word is spelled incorrectly due to a homophone. (typing peace instead of piece or typing abyss instead of abiss). The justification for implementing Real-word spelling errors comes from a statistic I found while researcher. It states the roughly 25-40% of spelling errors are real words (Kukich 1992).\n",
    "\n",
    "\n",
    "\n",
    "#### 6. Collecting more data\n",
    "\n",
    "The collection of more (high quality) data would have increased the overall effectiveness of our spellchecking system. Not only does more data result in more accurate results, but it always increases the size of the model's dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'white', 'cat']\n"
     ]
    }
   ],
   "source": [
    "def build_bigram_model(words_correct):\n",
    "    \n",
    "    bigram_counter = defaultdict(int)\n",
    "    text = []\n",
    "    # turn list into string\n",
    "    for i in words_correct:\n",
    "        text.append(\" \".join(i).lower())\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "    # '.bigrams' calculates frequency distribution\n",
    "    bigrams = nltk.bigrams(text)\n",
    "\n",
    "    for b in bigrams:\n",
    "        bigram_counter[b] += 1\n",
    "\n",
    "    return bigram_counter\n",
    "\n",
    "def correct_upgraded(sentence, unigram_model, bigram_model):\n",
    "    # Write your code here\n",
    "    result = []\n",
    "\n",
    "\n",
    "    for idx, word in enumerate(sentence):\n",
    "        if word in unigram_model:\n",
    "            result.append(word)\n",
    "        else:\n",
    "            correction_candidates = min_edit_distance(word, all_words)\n",
    "            best_prod, best_word = 0, None\n",
    "\n",
    "            # try to use bigram model\n",
    "            for c in correction_candidates:\n",
    "                word_prob = bigram_model[(sentence[idx - 1], c)] / (float(unigram_model[c]) + 1)\n",
    "                if word_prob > best_prod:\n",
    "                    best_prod = word_prob\n",
    "                    best_word = c\n",
    "\n",
    "            # fall back to unigram model\n",
    "            for c in correction_candidates:\n",
    "                word_prob = prob(c, unigram_model)\n",
    "                if word_prob > best_prod:\n",
    "                    best_prod = word_prob\n",
    "                    best_word = c\n",
    "\n",
    "            result.append(best_word)\n",
    "\n",
    "    return result\n",
    "\n",
    "bigram_model = build_bigram_model(words_correct)\n",
    "\n",
    "\n",
    "print(correct_upgraded([\"this\",\"whitr\",\"cat\"], unigram_model, bigram_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLzaC6D28sK9"
   },
   "source": [
    "## **Task 7 (5 Marks):**\n",
    "\n",
    "Repeat the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hw6PzwWn7iEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Method: 0.23728813559322035\n",
      "New Method: 0.288135593220339\n"
     ]
    }
   ],
   "source": [
    "def accuracy_upgraded(test):\n",
    "    correct_count, total = 0.0, 0.0\n",
    "    for sentence in test:\n",
    "        original_sentence = sentence['original']\n",
    "        corrected_sentence = correct_upgraded(original_sentence, unigram_model, bigram_model)\n",
    "\n",
    "        true_corrected = sentence['corrected']\n",
    "        for idx in sentence['indexes']:\n",
    "            if corrected_sentence[idx] == true_corrected[idx]:\n",
    "                correct_count += 1\n",
    "            total += 1\n",
    "    return correct_count / total\n",
    "\n",
    "\n",
    "print('Original Method: {}'.format(accuracy(test)))\n",
    "print('New Method: {}'.format(accuracy_upgraded(test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My original language model performed with 23.73% accuracy. After modification my upgraded language model performed with 28.81% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Work Cited\n",
    "All knowledge from this Natural Language Process report can be attributed to my NLP course as well as the resources listed below:\n",
    "\n",
    "\n",
    "Chris Manning, Hinrich Schuetze \"Foundations of Statistical Natural Language Processing\", MIT Press. Cambridge, MA: May 1999. Teaching materials online at: http://nlp.stanford.edu/fsnlp/\n",
    "\n",
    "Daniel Jurafsky, James H. Martin \"Speech and Language Processing - An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition”, Pearson, Prentice Hall, second edition. ISBN-10: 0131873210. Third Edition draft: https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf\n",
    "\n",
    "David Sunby \"Spelling correction using N-grams\"\n",
    "http://fileadmin.cs.lth.se/cs/education/EDA171/Reports/2009/david.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP 18/19 Assignment 1",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
